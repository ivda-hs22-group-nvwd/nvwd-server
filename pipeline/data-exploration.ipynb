{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from preprocess import preprocess\n",
    "from preprocess import normalize\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import sqlite3 as sq\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/profiles_revised.csv')\n",
    "df.columns = df.columns.str.replace('\\t', '') # needed?\n",
    "origin = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_col_values(list, filename):\n",
    "    with open(r'{}.txt'.format(filename), 'w') as fp:\n",
    "        for element in list:\n",
    "            fp.write(\"{}\\n\".format(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_distinct_values(df, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs('./exploration/'+folder)\n",
    "    for (index, colname) in enumerate(df.columns):\n",
    "        #print(index, colname)\n",
    "        distinc_values = df[colname].unique()\n",
    "        print_col_values(list=distinc_values, filename='./exploration/{}/{}-{}-values'.format(folder, index, colname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_values(df=df, folder='origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title='Pandas Profilign Report')\n",
    "#profile.to_notebook_iframe()\n",
    "#profile.to_file('./exploration/pandas_profiling_data_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[['age', 'body_type']]\n",
    "df_clean = preprocess(df.columns, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix '\\'\n",
    "#df_distinct_values(df=df_clean, folder='cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('./data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_name = 'okcupid_clean'\n",
    "#table_path = './data/'+ table_name +'_db'\n",
    "#conn = sq.connect('{}.sqlite'.format(table_path)) # creates file\n",
    "#df_clean.to_sql(table_path, conn, if_exists='replace', index=False) # writes to file\n",
    "#conn.close() # good practice: close connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANDARDIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()\n",
    "sample = df_clean.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['age', 'height']\n",
    "categorical_cols = ['body_type', 'drinks', 'drugs', 'income', 'job', 'orientation', 'sex', 'smokes',\n",
    "'diet','diet_modifier',\n",
    "'education_status', 'education_institution',\n",
    "'offspring_status', 'offspring_future',\n",
    "'pets_cats', 'pets_dogs',\n",
    "'religion_type', 'religion_modifier',\n",
    "'sign', 'sign_modifier']\n",
    "ethnities_cols = df_clean[df_clean.columns[pd.Series(df_clean.columns).str.startswith('ethnicities')]].columns\n",
    "speaks_cols = df_clean[df_clean.columns[pd.Series(df_clean.columns).str.startswith('speaks')]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "mapper = DataFrameMapper([\n",
    "  ('body_type', LabelEncoder()),\n",
    "  (['age'], StandardScaler())],\n",
    "  #[(categorical_col, LabelBinarizer()) for categorical_col in categorical_cols],\n",
    "  df_out=True \n",
    ")\n",
    "print(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper for checking\n",
    "mapper = DataFrameMapper([\n",
    "  #('drinks', LabelEncoder()),\n",
    "  (['age'], StandardScaler())] +\n",
    "  [(categorical_col, LabelBinarizer()) for categorical_col in categorical_cols],\n",
    "  df_out=True \n",
    ")\n",
    "print(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real mapper\n",
    "mapper = DataFrameMapper(\n",
    "  [([continuous_col], StandardScaler()) for continuous_col in continuous_cols] +\n",
    "  [(categorical_col, LabelEncoder()) for categorical_col in categorical_cols] +\n",
    "  [(ethnities_col, LabelEncoder()) for ethnities_col in ethnities_cols] +\n",
    "  [(speaks_col, LabelEncoder()) for speaks_col in speaks_cols],\n",
    "  df_out=True \n",
    ")\n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = np.round(mapper.fit_transform(df_clean.copy()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_name = 'okcupid_std'\n",
    "#table_path = './data/'+ table_name +'_db'\n",
    "#conn = sq.connect('{}.sqlite'.format(table_path)) # creates file\n",
    "#std_df.to_sql(table_path, conn, if_exists='replace', index=False) # writes to file\n",
    "#conn.close() # good practice: close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['okcupid_clean', 'okcupid_std']\n",
    "#table_path = './data/'+ table_name +'_db'\n",
    "\n",
    "dfs = {\n",
    "    \"std_clean\": df_clean,\n",
    "    \"dt_std\": df_std,\n",
    "}\n",
    "\n",
    "with sq.connect(\"okcupid.sqlite\") as db:\n",
    "    df_clean.to_sql('okcupid_clean', db, if_exists=\"replace\", index=False)\n",
    "    df_std.to_sql('okcupid_std', db, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = pd.DataFrame({'age': [30], 'body_type': ['fit']})\n",
    "#np.round(mapper.transform(sample), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(mapper.transform(sample), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "# https://stackoverflow.com/questions/43554821/feature-preprocessing-of-both-continuous-and-categorical-variables-of-integer-t\n",
    "# https://stackoverflow.com/questions/53152627/saving-standardscaler-model-for-use-on-new-datasets?noredirect=1&lq=1\n",
    "# https://stackoverflow.com/questions/38780302/predicting-new-data-using-sklearn-after-standardizing-the-training-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(df.corr(), center=0, annot=True)\n",
    "plt.title('Correlation Map')\n",
    "plt.show()\n",
    "plt.savefig('./exploration/correlation-map.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.pairplot(data=df, hue='lables', palette='RdBu')\n",
    "plt.title('Correlation Map')\n",
    "plt.show()\n",
    "plt.savefig('./exploration/pairplot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1810ffdbcb71ae5fcf06025e105de04d63893ffcafad0347f47a9509230b92c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
