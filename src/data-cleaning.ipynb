{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # DEBUG\n",
    "from glob import glob\n",
    "from pandas_profiling import ProfileReport\n",
    "import yaml\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ABS_SRC = os.getcwd()\n",
    "PATH_REL = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mapping File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"naming.yaml\") as stream:\n",
    "    naming = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/profiles_revised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title='Pandas Profilign Report')\n",
    "#profile.to_widgets() # does not show anything\n",
    "profile.to_notebook_iframe()\n",
    "profile.to_file(\"pandas_profiling_data_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_col_values(list, filename):\n",
    "    with open(r'{}.txt'.format(filename), 'w') as fp:\n",
    "        for element in list:\n",
    "            fp.write(\"{}\\n\".format(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zodiac Sign"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Col\n",
    "zodiacs = df.sign.unique()\n",
    "print_col_values(list=zodiacs, filename='zodiacs')\n",
    "\n",
    "ZODIAC_STRING_REPLACMENT = '&rsquo;' # corresponds to \" ' \"\n",
    "\n",
    "# Clean\n",
    "zodiacs = [z for z in zodiacs if str(z) != 'nan'] # remove nan values\n",
    "zodiacs = [v.replace('&rsquo;', '\\'') for v in zodiacs] # replace '\n",
    "\n",
    "# Check\n",
    "print_col_values(list=zodiacs, filename='zodiacs-cleaned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy by value\n",
    "df_zodiac = df.copy()\n",
    "\n",
    "# nan's, and spelling\n",
    "df_zodiac.dropna(inplace=True, subset=['sign']) # remove nan's\n",
    "df_zodiac.shape # (48890, 19) , same as profiler\n",
    "\n",
    "# extract only sign\n",
    "df_zodiac['sign-extracted'] = df_zodiac['sign'].str.split(' ').str[0]\n",
    "\n",
    "# extract sign modifier\n",
    "df_zodiac['sign-modifier-extracted'] = df_zodiac['sign'].str.split(' ').str[1:]\n",
    "df_zodiac['sign-modifier-extracted'] = df_zodiac['sign-modifier-extracted'].apply(lambda y: '' if len(y)==0 else y) # replace empty lists with ''\n",
    "df_zodiac['sign-modifier-extracted'] = df_zodiac['sign-modifier-extracted'].apply(lambda y: ' '.join(y) if len(y)!=0 else y) # join list of strings together\n",
    "df_zodiac['sign-modifier-extracted'] = df_zodiac['sign-modifier-extracted'].str.replace(ZODIAC_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "# map sign modifier + ordinal classifier\n",
    "mapper_naming_dict = naming['zodiac_hiearchy'] \n",
    "df_zodiac['sign-modifier-extracted-ordinal'] =  df_zodiac['sign-modifier-extracted'].map(mapper_naming_dict).fillna(df_zodiac['sign-modifier-extracted']) # map values from dict according to string\n",
    "df_zodiac[['sign', 'sign-extracted', 'sign-modifier-extracted', 'sign-modifier-extracted-ordinal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy by value\n",
    "df_languages = df.copy()\n",
    "\n",
    "# nan's\n",
    "df_languages.dropna(inplace=True, subset=['speaks']) # remove nan's\n",
    "df_languages.shape # (59896, 19) , same as profiler\n",
    "\n",
    "df_languages['spoken_languages'] = np.nan\n",
    "# structure: language (level), langauge2 .... || language, langauge2, ...\n",
    "# due to the n:m relationship between persons and languages we will choose a one key encoding for the data\n",
    "# to not overload the main dataframe we will create a separate df with the information of the languages and use teh same ID as in the main dataframe. The structure of the new df will look as followed:\n",
    "\n",
    "########################################################\n",
    "#  ID #  english  #  italian  #  spanish  # ... other # number of languages spoken\n",
    "#  1       1           0           0         0    1           2\n",
    "#  2       1           1           1         1    1           5\n",
    "#  3       0           1           1         0    1           3\n",
    "#  4       1           0           0         0    0           1\n",
    "#  5       1           0           1         0    1           3\n",
    "#\n",
    "# extract language, without level => split by comma => multiple values, split by space, use first\n",
    "#\n",
    "\n",
    "# iterate through all values and create lists for all languages, userIDs and column names\n",
    "allLanguages = list()\n",
    "allIds = list()\n",
    "languageColumns = list()\n",
    "for row in df_languages.iterrows():\n",
    "    languages = list()\n",
    "    idsForPerson = list()\n",
    "    # in this step the language is extracted (the appendix (spoken level e.g. fluid) removed)\n",
    "    for language in row[1].speaks.split(','):\n",
    "        languages.append(language.strip().split(' ')[0])\n",
    "        # indexes are going to be added to the list for the next step (one hot key encoding)\n",
    "        idsForPerson.append(row[0])\n",
    "        languageColumns.append(language.strip().split(' ')[0])\n",
    "    # allLanguages represents a list of languages [english, french, spanish]\n",
    "    allLanguages.append(languages)\n",
    "    # allIds represents a the list of the corresponding index [6, 6, 6] (for the lambda below)\n",
    "    allIds.append(idsForPerson)\n",
    "\n",
    "# remove all the duplicates from the column list\n",
    "languageColumns = sorted(set(languageColumns))\n",
    "encoded_df_languages = pd.DataFrame()\n",
    "df_languages['language'] = allLanguages\n",
    "encoded_df_languages['language'] = allLanguages\n",
    "encoded_df_languages['userID'] = allIds\n",
    "\n",
    "# split up the values from the array into new rows\n",
    "# [english, french, spanish] will be 3 rows with the corresponding userID of 6, 6, 6 => df gets form 60k rows to 110k\n",
    "encoded_df_languages =encoded_df_languages.apply(lambda x: pd.Series(np.concatenate(x.tolist())), 0)\n",
    "\n",
    "#creating instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on 'language' column\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(encoded_df_languages[['language']]).toarray())\n",
    "encoder_df.columns = languageColumns\n",
    "# join the new encoded df with the language one\n",
    "encoded_df_languages = encoded_df_languages.join(encoder_df)\n",
    "encoded_df_languages.drop(['language'], axis=1, inplace=True)\n",
    "# group the user that the languages are shown in one row => back to 60k rows\n",
    "encoded_df_languages.groupby('userID').sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Body Type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Diet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drugs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drinks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Education"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ethnicity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Income"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Job"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Offspring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Orientation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Religion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Smokes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Status"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Height"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1810ffdbcb71ae5fcf06025e105de04d63893ffcafad0347f47a9509230b92c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
