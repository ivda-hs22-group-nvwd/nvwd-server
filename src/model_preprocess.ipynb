{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONST\n",
    "ZODIAC_STRING_REPLACMENT = '&rsquo;' # corresponds to \" ' \"\n",
    "OFFSPRING_STRING_REPLACMENT = '&rsquo;' # corresponds to \" ' \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "# Using standard scaler\n",
    "def std_scaler(df, col_names):\n",
    "    scaled_features = df.copy()\n",
    " \n",
    "    features = scaled_features[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    " \n",
    "    scaled_features[col_names] = features\n",
    "\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "# Using min/max scaler\n",
    "def minmax_scaler(df, col_names):\n",
    "    scaled_features = df.copy()\n",
    " \n",
    "    features = scaled_features[col_names]\n",
    "    scaler = MinMaxScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    " \n",
    "    scaled_features[col_names] = features\n",
    "\n",
    "    return scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/profiles_revised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGE ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['age'])\n",
    "\n",
    "# Scale\n",
    "df = std_scaler(df, ['age'])\n",
    "\n",
    "\n",
    "### BODY_TYPE ###\n",
    "# Remove nan's\n",
    "\n",
    "df.dropna(inplace=True, subset=['body_type'])\n",
    "\n",
    "# Encode body type\n",
    "body_type_encoder = LabelEncoder()\n",
    "body_type_encoder.fit(df['body_type'])\n",
    "encoded_col_body_type = body_type_encoder.transform(df['body_type'])\n",
    "df['body_type'] = encoded_col_body_type\n",
    "\n",
    "### DIET ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['diet'])\n",
    "\n",
    "# Extract only diet\n",
    "df['diet_extracted'] = df['diet'].str.split(' ').str[-1]\n",
    "\n",
    "# Extract diet modifier\n",
    "df['diet_modifier_extracted'] = df['diet'].str.split(' ').str[:-1]\n",
    "df['diet_modifier_extracted'] = df['diet_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y[0]) # replace empty lists with '' and extract term from list\n",
    "\n",
    "# Todo: Consultation whether further mapping makes sense\n",
    "\n",
    "# Encode diet\n",
    "diet_encoder = LabelEncoder()\n",
    "diet_encoder.fit(df['diet_extracted'])\n",
    "encoded_col_diet = diet_encoder.transform(df['diet_extracted'])\n",
    "df['diet'] = encoded_col_diet\n",
    "\n",
    "# Encode diet modifier\n",
    "diet_modifier_encoder = LabelEncoder()\n",
    "diet_modifier_encoder.fit(df['diet_modifier_extracted'])\n",
    "encoded_col_diet_modifier = diet_modifier_encoder.transform(df['diet_modifier_extracted'])\n",
    "df['diet_modifier'] = encoded_col_diet_modifier\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('diet_extracted', axis=1)\n",
    "df = df.drop('diet_modifier_extracted', axis=1)\n",
    "\n",
    "### DRINKS ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['drinks'])\n",
    "\n",
    "# Encode drinks modifier\n",
    "drinks_encoder = LabelEncoder()\n",
    "drinks_encoder.fit(df['drinks'])\n",
    "encoded_col_drinks = drinks_encoder.transform(df['drinks'])\n",
    "df['drinks'] = encoded_col_drinks\n",
    "\n",
    "\n",
    "### DRUGS ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['drugs'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "drinks_encoder = LabelEncoder()\n",
    "drinks_encoder.fit(df['drugs'])\n",
    "encoded_col_drugs = drinks_encoder.transform(df['drugs'])\n",
    "df['drugs'] = encoded_col_drugs\n",
    "\n",
    "\n",
    "### EDUCATION ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['education'])\n",
    "\n",
    "\n",
    "# Extract only education institution\n",
    "# todo find better solution to use the dedicated mapper in naming.yaml\n",
    "def education_institution_mapper(x):\n",
    "    if 'college/university' in x:\n",
    "        return 'college/university'\n",
    "    if 'two-year college' in x:\n",
    "        return 'two-year college'\n",
    "    if 'masters program' in x:\n",
    "        return 'masters program'\n",
    "    if 'ph.d program' in x:\n",
    "        return 'ph.d program'\n",
    "    if 'high school' in x:\n",
    "        return 'high school'\n",
    "    if 'law school' in x:\n",
    "        return 'law school'\n",
    "    if 'med school' in x:\n",
    "        return 'med school'\n",
    "    if 'space camp' in x:\n",
    "        return 'space camp'\n",
    "\n",
    "# Extract only education status\n",
    "def education_status_mapper(x):\n",
    "    if 'dropped out of' in x:\n",
    "        return 'dropped out of'\n",
    "    if 'working on' in x:\n",
    "        return 'working on'\n",
    "    if 'graduated from' in x:\n",
    "        return 'graduated from'\n",
    "\n",
    "\n",
    "df['education_status_extracted'] = df['education'].apply(lambda x: education_status_mapper(x))\n",
    "df['education_institution_extracted'] = df['education'].apply(lambda x: education_institution_mapper(x))\n",
    "\n",
    "\n",
    "# Encode education_status\n",
    "education_status_encoder = LabelEncoder()\n",
    "education_status_encoder.fit(df['education_status_extracted'])\n",
    "encoded_col_education_status = education_status_encoder.transform(df['education_status_extracted'])\n",
    "df['education_status_extracted'] = encoded_col_education_status\n",
    "\n",
    "# Encode diet modifier\n",
    "education_institution_encoder = LabelEncoder()\n",
    "education_institution_encoder.fit(df['education_institution_extracted'])\n",
    "encoded_col_education_institution = education_institution_encoder.transform(df['education_institution_extracted'])\n",
    "df['education_institution_extracted'] = encoded_col_education_institution\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('education', axis=1)\n",
    "\n",
    "\n",
    "### ETHNICITY ###\n",
    "\n",
    "# Extract all ethnicities categories\n",
    "# Get all distinct values for the ethnicity  col\n",
    "ethnicities = df.ethnicity.unique()\n",
    "\n",
    "# Clean\n",
    "ethnicities = [e for e in ethnicities if str(e) != 'nan'] # remove nan values\n",
    "\n",
    "# Extract all ethnicities combinations \n",
    "ethnicities = ', '.join(ethnicities)\n",
    "ethnicities = ethnicities.split(', ') \n",
    "ethnicities = [*set(ethnicities)] # create list of \"base\" ethnicities\n",
    "\n",
    "# Generate new header for encoded categories\n",
    "ethnicities_encoded_header = ['ethnicities_{}'.format(e.replace(' ', '_')) for e in ethnicities]\n",
    "\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['ethnicity'])\n",
    "\n",
    "# Add col header\n",
    "for eth_col in ethnicities_encoded_header:\n",
    "    df[eth_col] = np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_ethnicities(col, row_ethnicities):\n",
    "    # extract all ethnicities from the col 'ethnicity'\n",
    "    row_ethnicities = row_ethnicities.split(', ')\n",
    "    \n",
    "    # compare all extracted to current row in df\n",
    "    for re in row_ethnicities:\n",
    "        # match\n",
    "        if re == col:\n",
    "            return 1\n",
    "    # no match\n",
    "    return 0\n",
    "\n",
    "# Hot encoding for all ethnicities cols\n",
    "for (ethnicities_encoded_header_col, e) in zip(ethnicities_encoded_header, ethnicities):\n",
    "    df[ethnicities_encoded_header_col] = df.apply(lambda x: filter_ethnicities(e, x['ethnicity']), axis=1)\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('ethnicity', axis=1)\n",
    "\n",
    "\n",
    "### HEIGHT ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['height'])\n",
    "\n",
    "# Scale\n",
    "df = std_scaler(df, ['height'])\n",
    "\n",
    "\n",
    "### INCOME ###\n",
    "\n",
    "# Replace -1 entries\n",
    "df['income'] = df['income'].apply(lambda y: np.nan if y==-1 else y) # replace -1 with nan\n",
    "# Todo: Maybe insert non nan but average income (only 5k values after that)\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['income'])\n",
    "\n",
    "# Scale\n",
    "df = std_scaler(df, ['income'])\n",
    "#df\n",
    "\n",
    "df = df.drop('income', axis=1)\n",
    "\n",
    "\n",
    "### JOB ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['job'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "job_encoder = LabelEncoder()\n",
    "job_encoder.fit(df['job'])\n",
    "encoded_col_job = job_encoder.transform(df['job'])\n",
    "df['job'] = encoded_col_job\n",
    "\n",
    "\n",
    "### OFFSPRING  ###\n",
    "\n",
    "# Extract all offspring categories\n",
    "# todo: automate\n",
    "\n",
    "OFFSPRING_STATUS_ORIG = [\n",
    "    'doesn\\'t have kids', 'has a kid', 'has kids'] # STATUS\n",
    "\n",
    "\n",
    "OFFSPRING_FUTURE_ORIG = [\n",
    "    'and doesn\\'t want any', 'doesn\\'t want kids', 'but doesn\\'t want more',\n",
    "    'but might want them', 'might want kids', 'and might want more',\n",
    "    'wants kids', 'but wants them', 'and wants more'] # FUTURE\n",
    "\n",
    "OFFSPRING_FUTURE = [\n",
    "    'doesn\\'t want',\n",
    "    'might want',\n",
    "    'wants'\n",
    "]\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['offspring'])\n",
    "\n",
    "df['offspring'] = df['offspring'].str.replace(OFFSPRING_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "offspring_encoded_header = ['offspring_status', 'offspring_future']\n",
    "\n",
    "# Add col header\n",
    "for off_col in offspring_encoded_header:\n",
    "    df[off_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_offspring_status(row_offspring):    \n",
    "    # compare all extracted to current row in df\n",
    "    for status in OFFSPRING_STATUS_ORIG:\n",
    "        if status in row_offspring:\n",
    "            # match\n",
    "            return status\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_offspring_future(row_offspring):    \n",
    "    # compare all extracted to current row in df\n",
    "    for future in OFFSPRING_FUTURE:\n",
    "        if future in row_offspring:\n",
    "            # match\n",
    "            return future\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['offspring_status'] = df.apply(lambda x: filter_offspring_status(x['offspring']), axis=1)\n",
    "df['offspring_future'] = df.apply(lambda x: filter_offspring_future(x['offspring']), axis=1)\n",
    "\n",
    "df.dropna(inplace=True, subset=['offspring_status'])\n",
    "df.dropna(inplace=True, subset=['offspring_future'])\n",
    "\n",
    "\n",
    "# Encode offspring_status\n",
    "offspring_status_encoder = LabelEncoder()\n",
    "offspring_status_encoder.fit(df['offspring_status'])\n",
    "encoded_col_offspring_status = offspring_status_encoder.transform(df['offspring_status'])\n",
    "df['offspring_status'] = encoded_col_offspring_status\n",
    "\n",
    "# Encode offspring_future\n",
    "offspring_future_encoder = LabelEncoder()\n",
    "offspring_future_encoder.fit(df['offspring_future'])\n",
    "encoded_col_offspring_future = offspring_future_encoder.transform(df['offspring_future'])\n",
    "df['offspring_future'] = encoded_col_offspring_future\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('offspring', axis=1)\n",
    "\n",
    "\n",
    "### OFFSPRING ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['orientation'])\n",
    "\n",
    "# Encode orientation\n",
    "orientation_encoder = LabelEncoder()\n",
    "orientation_encoder.fit(df['orientation'])\n",
    "encoded_col_orientation = orientation_encoder.transform(df['orientation'])\n",
    "df['orientation'] = encoded_col_orientation\n",
    "\n",
    "\n",
    "### PETS ###\n",
    "\n",
    "# Extract all pets categories\n",
    "# todo: automate\n",
    "\n",
    "PETS_CATS = [\n",
    "    'has cats', 'likes cats', 'dislikes cats']\n",
    "\n",
    "PETS_DOGS = [\n",
    "    'has dogs', 'likes dogs', 'dislikes dogs']\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['pets'])\n",
    "\n",
    "\n",
    "pets_encoded_header = ['pets_cats', 'pets_dogs']\n",
    "\n",
    "# Add col header\n",
    "for pets_col in pets_encoded_header:\n",
    "    df[pets_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_pets_cats(row_pets):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relation in PETS_CATS:\n",
    "        if relation in row_pets:\n",
    "            # match\n",
    "            return relation\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_pets_dogs(row_pets):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relation in PETS_DOGS:\n",
    "        if relation in row_pets:\n",
    "            # match\n",
    "            return relation\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['pets_cats'] = df.apply(lambda x: filter_pets_cats(x['pets']), axis=1)\n",
    "df['pets_dogs'] = df.apply(lambda x: filter_pets_dogs(x['pets']), axis=1)\n",
    "\n",
    "df.dropna(inplace=True, subset=['pets_cats'])\n",
    "df.dropna(inplace=True, subset=['pets_dogs'])\n",
    "\n",
    "\n",
    "# Encode pets_cats\n",
    "pets_cats_encoder = LabelEncoder()\n",
    "pets_cats_encoder.fit(df['pets_cats'])\n",
    "encoded_col_pets_cats = pets_cats_encoder.transform(df['pets_cats'])\n",
    "df['pets_cats'] = encoded_col_pets_cats\n",
    "\n",
    "# Encode pets_dogs\n",
    "pets_dogs_encoder = LabelEncoder()\n",
    "pets_dogs_encoder.fit(df['pets_dogs'])\n",
    "encoded_col_pets_dogs = pets_dogs_encoder.transform(df['pets_dogs'])\n",
    "df['pets_dogs'] = encoded_col_pets_dogs\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('pets', axis=1)\n",
    "\n",
    "\n",
    "### RELIGION ###\n",
    "\n",
    "# Extract all offspring categories\n",
    "# todo: automate\n",
    "\n",
    "# Extract all religion categories\n",
    "# Get all distinct values for the religion  col\n",
    "religion = df.religion.unique()\n",
    "\n",
    "# Clean\n",
    "religion = [r for r in religion if str(r) != 'nan'] # remove nan values\n",
    "\n",
    "# Extract all religion types\n",
    "religion_types = []\n",
    "religion_modifiers = [] \n",
    "for r in religion:\n",
    "    # extraxt first half: up to 'and' or 'but'\n",
    "    if 'and' in r:\n",
    "        religion_extracted = r.split('and')[0]\n",
    "    elif 'but' in r:\n",
    "        religion_extracted = r.split('but')[0]\n",
    "    else:\n",
    "        religion_extracted = r\n",
    "    religion_types.append(religion_extracted)\n",
    "   \n",
    "for r in religion:\n",
    "    # extraxt first half: up to 'and' or 'but'\n",
    "    if 'and' in r:\n",
    "        religion_modifier_extracted = r.split('and')[1]\n",
    "    elif 'but' in r:\n",
    "        religion_modifier_extracted = r.split('but')[1]\n",
    "    \n",
    "    religion_modifiers.append(religion_modifier_extracted)\n",
    "\n",
    "\n",
    "religion_types = [*set(religion_types)] # create list of \"base\" religions\n",
    "\n",
    "\n",
    "religion_modifiers = [*set(religion_modifiers)] # create list of religion modifiers\n",
    "\n",
    "\n",
    "RELIGION_TYPES = religion_types\n",
    "RELIGION_MODIFIERS = religion_modifiers\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['religion'])\n",
    "\n",
    "relgion_encoded_header = ['religion_type', 'religion_modifier']\n",
    "\n",
    "# Add col header\n",
    "for rel_col in relgion_encoded_header:\n",
    "    df[rel_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_religion_type(row_religion):    \n",
    "    # compare all extracted to current row in df\n",
    "    for type in RELIGION_TYPES:\n",
    "        if type in row_religion:\n",
    "            # match\n",
    "            return type\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_religion_modifier(row_religion):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relmodifier in RELIGION_MODIFIERS:\n",
    "        if relmodifier in row_religion:\n",
    "            # match\n",
    "            return relmodifier\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['religion_type'] = df.apply(lambda x: filter_religion_type(x['religion']), axis=1)\n",
    "df['religion_modifier'] = df.apply(lambda x: filter_religion_modifier(x['religion']), axis=1)\n",
    "\n",
    "################## COMMENT OUT FOR FRONTEND\n",
    "df.dropna(inplace=True, subset=['religion_type'])\n",
    "df.dropna(inplace=True, subset=['religion_modifier'])\n",
    "\n",
    "\n",
    "# Encode religion_type\n",
    "religion_type_encoder = LabelEncoder()\n",
    "religion_type_encoder.fit(df['religion_type'])\n",
    "encoded_col_religion_type = religion_type_encoder.transform(df['religion_type'])\n",
    "df['religion_type'] = encoded_col_religion_type\n",
    "\n",
    "# Encode religion_modifier\n",
    "religion_modifier_encoder = LabelEncoder()\n",
    "religion_modifier_encoder.fit(df['religion_modifier'])\n",
    "encoded_col_religion_modifier = religion_modifier_encoder.transform(df['religion_modifier'])\n",
    "df['religion_modifier'] = encoded_col_religion_modifier\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('religion', axis=1)\n",
    "\n",
    "\n",
    "### SEX ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['sex'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "sex_encoder = LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "encoded_col_sex = sex_encoder.transform(df['sex'])\n",
    "df['sex'] = encoded_col_sex\n",
    "\n",
    "\n",
    "### SIGN ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['sign'])\n",
    "\n",
    "\n",
    "# Extract only sign\n",
    "df['sign_extracted'] = df['sign'].str.split(' ').str[0]\n",
    "\n",
    "# Extract sign modifier\n",
    "df['sign_modifier_extracted'] = df['sign'].str.split(' ').str[1:]\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y) # replace empty lists with ''\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: ' '.join(y) if len(y)!=0 else y) # join list of strings together\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].str.replace(ZODIAC_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "################## COMMENT OUT FOR FRONTEND\n",
    "# Encode sign\n",
    "sign_encoder = LabelEncoder()\n",
    "sign_encoder.fit(df['sign_extracted'])\n",
    "encoded_col_sign = sign_encoder.transform(df['sign_extracted'])\n",
    "df['sign_extracted'] = encoded_col_sign\n",
    "\n",
    "# Encode sign modifier\n",
    "sign_modifier_encoder = LabelEncoder()\n",
    "sign_modifier_encoder.fit(df['sign_modifier_extracted'])\n",
    "encoded_col_sign_modifier = sign_modifier_encoder.transform(df['sign_modifier_extracted'])\n",
    "df['sign_modifier_extracted'] = encoded_col_sign_modifier\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('sign', axis=1)\n",
    "\n",
    "\n",
    "### SMOKES ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['smokes'])\n",
    "\n",
    "# Encode smokes modifier\n",
    "smokes_encoder = LabelEncoder()\n",
    "smokes_encoder.fit(df['smokes'])\n",
    "encoded_col_smokes = smokes_encoder.transform(df['smokes'])\n",
    "df['smokes'] = encoded_col_smokes\n",
    "\n",
    "\n",
    "### SPEAKS ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['speaks'])\n",
    "\n",
    "languages = df.speaks.unique()\n",
    "\n",
    "language = []\n",
    "language_level = []\n",
    "\n",
    "for l in languages:\n",
    "    entries = l.split(', ')\n",
    "    for e in entries:\n",
    "\n",
    "        # at least on entry that has a modifier\n",
    "        if e.find('(') != -1:\n",
    "            # extract modifier\n",
    "            res = e[e.find('(')+1:e.find(')')]\n",
    "            \n",
    "            # check if modifier can be appended\n",
    "            if res not in language_level:\n",
    "                language_level.append(res)\n",
    "            \n",
    "            # check if language can be appended\n",
    "            if e[:e.find(' ')]:\n",
    "                if e[:e.find(' ')] not in language:\n",
    "                    language.append(e[:e.find(' ')])\n",
    "        \n",
    "        # no modifier\n",
    "        else:\n",
    "            # check if language can be appended\n",
    "            if e not in language:\n",
    "                language.append(e)\n",
    "\n",
    "\n",
    "SPEAKS_LANGUAGE = language\n",
    "SPEAKS_LANGUAGE_LEVEL = language_level\n",
    "\n",
    "speaks_encoded_header = [l.replace(' ', '_') for l in SPEAKS_LANGUAGE]\n",
    "\n",
    "# Add col header\n",
    "for speaks_col in speaks_encoded_header:\n",
    "    df['speaks_'+speaks_col] = np.nan\n",
    "\n",
    "speaks_encoded_header = ['speaks_'+l for l in speaks_encoded_header]\n",
    "speaks_encoded_header = [l.replace(' ', '_') for l in speaks_encoded_header]\n",
    "\n",
    "\n",
    "# Filter\n",
    "def filter_speaks(s, row_speaks):    \n",
    "    # compare all extracted to current row in df\n",
    "\n",
    "    # split string into list of multiple langues + modifier\n",
    "    rs = row_speaks.split(', ')\n",
    "\n",
    "    # check if language s (current col) is in this list\n",
    "    res = [i for i in rs if s in i]\n",
    "    if len(res) != 0:\n",
    "        # modifier:\n",
    "        if '(fluently)' in res[0]:\n",
    "            return 4\n",
    "        if '(ok)' in res[0]:\n",
    "            return 3\n",
    "        if '(poorly)' in res[0]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        return 0 # maybe change to np.nan\n",
    "\n",
    "\n",
    "# Hot encoding for all speaks cols\n",
    "for (speaks_encoded_header_col, s) in zip(speaks_encoded_header, SPEAKS_LANGUAGE):\n",
    "    df[speaks_encoded_header_col] = df.apply(lambda x: filter_speaks(s, x['speaks']), axis=1)\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('speaks', axis=1)\n",
    "\n",
    "\n",
    "### STATUS ###\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['status'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "status_encoder = LabelEncoder()\n",
    "status_encoder.fit(df['status'])\n",
    "encoded_col_status = status_encoder.transform(df['status'])\n",
    "df['status'] = encoded_col_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(columns, df):\n",
    "\n",
    "\n",
    "    if 'age' in columns:\n",
    "        ### AGE ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['age'])\n",
    "\n",
    "        # Scale\n",
    "        df = std_scaler(df, ['age'])\n",
    "\n",
    "\n",
    "    if 'body_type' in columns:\n",
    "        ### BODY_TYPE ###\n",
    "        # Remove nan's\n",
    "\n",
    "        df.dropna(inplace=True, subset=['body_type'])\n",
    "\n",
    "        # Encode body type\n",
    "        body_type_encoder = LabelEncoder()\n",
    "        body_type_encoder.fit(df['body_type'])\n",
    "        encoded_col_body_type = body_type_encoder.transform(df['body_type'])\n",
    "        df['body_type'] = encoded_col_body_type\n",
    "\n",
    "    \n",
    "    if 'diet' in columns:\n",
    "        ### DIET ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['diet'])\n",
    "\n",
    "        # Extract only diet\n",
    "        df['diet_extracted'] = df['diet'].str.split(' ').str[-1]\n",
    "\n",
    "        # Extract diet modifier\n",
    "        df['diet_modifier_extracted'] = df['diet'].str.split(' ').str[:-1]\n",
    "        df['diet_modifier_extracted'] = df['diet_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y[0]) # replace empty lists with '' and extract term from list\n",
    "\n",
    "        # Todo: Consultation whether further mapping makes sense\n",
    "\n",
    "        # Encode diet\n",
    "        diet_encoder = LabelEncoder()\n",
    "        diet_encoder.fit(df['diet_extracted'])\n",
    "        encoded_col_diet = diet_encoder.transform(df['diet_extracted'])\n",
    "        df['diet'] = encoded_col_diet\n",
    "\n",
    "        # Encode diet modifier\n",
    "        diet_modifier_encoder = LabelEncoder()\n",
    "        diet_modifier_encoder.fit(df['diet_modifier_extracted'])\n",
    "        encoded_col_diet_modifier = diet_modifier_encoder.transform(df['diet_modifier_extracted'])\n",
    "        df['diet_modifier'] = encoded_col_diet_modifier\n",
    "\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('diet_extracted', axis=1)\n",
    "        df = df.drop('diet_modifier_extracted', axis=1)\n",
    "\n",
    "\n",
    "    if 'drinks' in columns:\n",
    "        ### DRINKS ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['drinks'])\n",
    "\n",
    "        # Encode drinks modifier\n",
    "        drinks_encoder = LabelEncoder()\n",
    "        drinks_encoder.fit(df['drinks'])\n",
    "        encoded_col_drinks = drinks_encoder.transform(df['drinks'])\n",
    "        df['drinks'] = encoded_col_drinks\n",
    "\n",
    "\n",
    "    if 'drugs' in columns:\n",
    "        ### DRUGS ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['drugs'])\n",
    "\n",
    "        # Encode drugs modifier\n",
    "        drinks_encoder = LabelEncoder()\n",
    "        drinks_encoder.fit(df['drugs'])\n",
    "        encoded_col_drugs = drinks_encoder.transform(df['drugs'])\n",
    "        df['drugs'] = encoded_col_drugs\n",
    "\n",
    "\n",
    "    if 'education' in columns:\n",
    "        ### EDUCATION ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['education'])\n",
    "\n",
    "\n",
    "        # Extract only education institution\n",
    "        # todo find better solution to use the dedicated mapper in naming.yaml\n",
    "        def education_institution_mapper(x):\n",
    "            if 'college/university' in x:\n",
    "                return 'college/university'\n",
    "            if 'two-year college' in x:\n",
    "                return 'two-year college'\n",
    "            if 'masters program' in x:\n",
    "                return 'masters program'\n",
    "            if 'ph.d program' in x:\n",
    "                return 'ph.d program'\n",
    "            if 'high school' in x:\n",
    "                return 'high school'\n",
    "            if 'law school' in x:\n",
    "                return 'law school'\n",
    "            if 'med school' in x:\n",
    "                return 'med school'\n",
    "            if 'space camp' in x:\n",
    "                return 'space camp'\n",
    "\n",
    "        # Extract only education status\n",
    "        def education_status_mapper(x):\n",
    "            if 'dropped out of' in x:\n",
    "                return 'dropped out of'\n",
    "            if 'working on' in x:\n",
    "                return 'working on'\n",
    "            if 'graduated from' in x:\n",
    "                return 'graduated from'\n",
    "\n",
    "\n",
    "        df['education_status_extracted'] = df['education'].apply(lambda x: education_status_mapper(x))\n",
    "        df['education_institution_extracted'] = df['education'].apply(lambda x: education_institution_mapper(x))\n",
    "\n",
    "\n",
    "        # Encode education_status\n",
    "        education_status_encoder = LabelEncoder()\n",
    "        education_status_encoder.fit(df['education_status_extracted'])\n",
    "        encoded_col_education_status = education_status_encoder.transform(df['education_status_extracted'])\n",
    "        df['education_status_extracted'] = encoded_col_education_status\n",
    "\n",
    "        # Encode diet modifier\n",
    "        education_institution_encoder = LabelEncoder()\n",
    "        education_institution_encoder.fit(df['education_institution_extracted'])\n",
    "        encoded_col_education_institution = education_institution_encoder.transform(df['education_institution_extracted'])\n",
    "        df['education_institution_extracted'] = encoded_col_education_institution\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('education', axis=1)\n",
    "\n",
    "\n",
    "    if 'ethnicity' in columns:\n",
    "        ### ETHNICITY ###\n",
    "\n",
    "        # Extract all ethnicities categories\n",
    "        # Get all distinct values for the ethnicity  col\n",
    "        ethnicities = df.ethnicity.unique()\n",
    "\n",
    "        # Clean\n",
    "        ethnicities = [e for e in ethnicities if str(e) != 'nan'] # remove nan values\n",
    "\n",
    "        # Extract all ethnicities combinations \n",
    "        ethnicities = ', '.join(ethnicities)\n",
    "        ethnicities = ethnicities.split(', ') \n",
    "        ethnicities = [*set(ethnicities)] # create list of \"base\" ethnicities\n",
    "\n",
    "        # Generate new header for encoded categories\n",
    "        ethnicities_encoded_header = ['ethnicities_{}'.format(e.replace(' ', '_')) for e in ethnicities]\n",
    "\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['ethnicity'])\n",
    "\n",
    "        # Add col header\n",
    "        for eth_col in ethnicities_encoded_header:\n",
    "            df[eth_col] = np.nan\n",
    "\n",
    "        # Filter\n",
    "        def filter_ethnicities(col, row_ethnicities):\n",
    "            # extract all ethnicities from the col 'ethnicity'\n",
    "            row_ethnicities = row_ethnicities.split(', ')\n",
    "            \n",
    "            # compare all extracted to current row in df\n",
    "            for re in row_ethnicities:\n",
    "                # match\n",
    "                if re == col:\n",
    "                    return 1\n",
    "            # no match\n",
    "            return 0\n",
    "\n",
    "        # Hot encoding for all ethnicities cols\n",
    "        for (ethnicities_encoded_header_col, e) in zip(ethnicities_encoded_header, ethnicities):\n",
    "            df[ethnicities_encoded_header_col] = df.apply(lambda x: filter_ethnicities(e, x['ethnicity']), axis=1)\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('ethnicity', axis=1)\n",
    "\n",
    "\n",
    "    if 'height' in columns:\n",
    "        ### HEIGHT ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['height'])\n",
    "\n",
    "        # Scale\n",
    "        df = std_scaler(df, ['height'])\n",
    "\n",
    "\n",
    "    if 'income' in columns:\n",
    "        ### INCOME ###\n",
    "\n",
    "        # Replace -1 entries\n",
    "        df['income'] = df['income'].apply(lambda y: np.nan if y==-1 else y) # replace -1 with nan\n",
    "        # Todo: Maybe insert non nan but average income (only 5k values after that)\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['income'])\n",
    "\n",
    "        # Scale\n",
    "        df = std_scaler(df, ['income'])\n",
    "        #df\n",
    "\n",
    "        df = df.drop('income', axis=1)\n",
    "\n",
    "\n",
    "    if 'job' in columns:\n",
    "        ### JOB ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['job'])\n",
    "\n",
    "        # Encode drugs modifier\n",
    "        job_encoder = LabelEncoder()\n",
    "        job_encoder.fit(df['job'])\n",
    "        encoded_col_job = job_encoder.transform(df['job'])\n",
    "        df['job'] = encoded_col_job\n",
    "\n",
    "\n",
    "    if 'offspring' in columns:\n",
    "        ### OFFSPRING  ###\n",
    "\n",
    "        # Extract all offspring categories\n",
    "        # todo: automate\n",
    "\n",
    "        OFFSPRING_STATUS_ORIG = [\n",
    "            'doesn\\'t have kids', 'has a kid', 'has kids'] # STATUS\n",
    "\n",
    "\n",
    "        OFFSPRING_FUTURE_ORIG = [\n",
    "            'and doesn\\'t want any', 'doesn\\'t want kids', 'but doesn\\'t want more',\n",
    "            'but might want them', 'might want kids', 'and might want more',\n",
    "            'wants kids', 'but wants them', 'and wants more'] # FUTURE\n",
    "\n",
    "        OFFSPRING_FUTURE = [\n",
    "            'doesn\\'t want',\n",
    "            'might want',\n",
    "            'wants'\n",
    "        ]\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['offspring'])\n",
    "\n",
    "        df['offspring'] = df['offspring'].str.replace(OFFSPRING_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "        offspring_encoded_header = ['offspring_status', 'offspring_future']\n",
    "\n",
    "        # Add col header\n",
    "        for off_col in offspring_encoded_header:\n",
    "            df[off_col] = np.nan\n",
    "\n",
    "        # Filer\n",
    "        def filter_offspring_status(row_offspring):    \n",
    "            # compare all extracted to current row in df\n",
    "            for status in OFFSPRING_STATUS_ORIG:\n",
    "                if status in row_offspring:\n",
    "                    # match\n",
    "                    return status\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "        # Filter\n",
    "        def filter_offspring_future(row_offspring):    \n",
    "            # compare all extracted to current row in df\n",
    "            for future in OFFSPRING_FUTURE:\n",
    "                if future in row_offspring:\n",
    "                    # match\n",
    "                    return future\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "        # Hot encoding for both offspring cols\n",
    "        df['offspring_status'] = df.apply(lambda x: filter_offspring_status(x['offspring']), axis=1)\n",
    "        df['offspring_future'] = df.apply(lambda x: filter_offspring_future(x['offspring']), axis=1)\n",
    "\n",
    "        df.dropna(inplace=True, subset=['offspring_status'])\n",
    "        df.dropna(inplace=True, subset=['offspring_future'])\n",
    "\n",
    "\n",
    "        # Encode offspring_status\n",
    "        offspring_status_encoder = LabelEncoder()\n",
    "        offspring_status_encoder.fit(df['offspring_status'])\n",
    "        encoded_col_offspring_status = offspring_status_encoder.transform(df['offspring_status'])\n",
    "        df['offspring_status'] = encoded_col_offspring_status\n",
    "\n",
    "        # Encode offspring_future\n",
    "        offspring_future_encoder = LabelEncoder()\n",
    "        offspring_future_encoder.fit(df['offspring_future'])\n",
    "        encoded_col_offspring_future = offspring_future_encoder.transform(df['offspring_future'])\n",
    "        df['offspring_future'] = encoded_col_offspring_future\n",
    "\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('offspring', axis=1)\n",
    "\n",
    "\n",
    "    if 'orientation' in columns:\n",
    "        ### ORIENTATION ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['orientation'])\n",
    "\n",
    "        # Encode orientation\n",
    "        orientation_encoder = LabelEncoder()\n",
    "        orientation_encoder.fit(df['orientation'])\n",
    "        encoded_col_orientation = orientation_encoder.transform(df['orientation'])\n",
    "        df['orientation'] = encoded_col_orientation\n",
    "\n",
    "\n",
    "    if 'pets' in columns:\n",
    "        ### PETS ###\n",
    "\n",
    "        # Extract all pets categories\n",
    "        # todo: automate\n",
    "\n",
    "        PETS_CATS = [\n",
    "            'has cats', 'likes cats', 'dislikes cats']\n",
    "\n",
    "        PETS_DOGS = [\n",
    "            'has dogs', 'likes dogs', 'dislikes dogs']\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['pets'])\n",
    "\n",
    "\n",
    "        pets_encoded_header = ['pets_cats', 'pets_dogs']\n",
    "\n",
    "        # Add col header\n",
    "        for pets_col in pets_encoded_header:\n",
    "            df[pets_col] = np.nan\n",
    "\n",
    "        # Filer\n",
    "        def filter_pets_cats(row_pets):    \n",
    "            # compare all extracted to current row in df\n",
    "            for relation in PETS_CATS:\n",
    "                if relation in row_pets:\n",
    "                    # match\n",
    "                    return relation\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "        # Filer\n",
    "        def filter_pets_dogs(row_pets):    \n",
    "            # compare all extracted to current row in df\n",
    "            for relation in PETS_DOGS:\n",
    "                if relation in row_pets:\n",
    "                    # match\n",
    "                    return relation\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "        # Hot encoding for both offspring cols\n",
    "        df['pets_cats'] = df.apply(lambda x: filter_pets_cats(x['pets']), axis=1)\n",
    "        df['pets_dogs'] = df.apply(lambda x: filter_pets_dogs(x['pets']), axis=1)\n",
    "\n",
    "        df.dropna(inplace=True, subset=['pets_cats'])\n",
    "        df.dropna(inplace=True, subset=['pets_dogs'])\n",
    "\n",
    "\n",
    "        # Encode pets_cats\n",
    "        pets_cats_encoder = LabelEncoder()\n",
    "        pets_cats_encoder.fit(df['pets_cats'])\n",
    "        encoded_col_pets_cats = pets_cats_encoder.transform(df['pets_cats'])\n",
    "        df['pets_cats'] = encoded_col_pets_cats\n",
    "\n",
    "        # Encode pets_dogs\n",
    "        pets_dogs_encoder = LabelEncoder()\n",
    "        pets_dogs_encoder.fit(df['pets_dogs'])\n",
    "        encoded_col_pets_dogs = pets_dogs_encoder.transform(df['pets_dogs'])\n",
    "        df['pets_dogs'] = encoded_col_pets_dogs\n",
    "\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('pets', axis=1)\n",
    "\n",
    "\n",
    "    if 'religion' in columns:\n",
    "        ### RELIGION ###\n",
    "\n",
    "        # Extract all offspring categories\n",
    "        # todo: automate\n",
    "\n",
    "        # Extract all religion categories\n",
    "        # Get all distinct values for the religion  col\n",
    "        religion = df.religion.unique()\n",
    "\n",
    "        # Clean\n",
    "        religion = [r for r in religion if str(r) != 'nan'] # remove nan values\n",
    "\n",
    "        # Extract all religion types\n",
    "        religion_types = []\n",
    "        religion_modifiers = [] \n",
    "        for r in religion:\n",
    "            # extraxt first half: up to 'and' or 'but'\n",
    "            if 'and' in r:\n",
    "                religion_extracted = r.split('and')[0]\n",
    "            elif 'but' in r:\n",
    "                religion_extracted = r.split('but')[0]\n",
    "            else:\n",
    "                religion_extracted = r\n",
    "            religion_types.append(religion_extracted)\n",
    "        \n",
    "        for r in religion:\n",
    "            # extraxt first half: up to 'and' or 'but'\n",
    "            if 'and' in r:\n",
    "                religion_modifier_extracted = r.split('and')[1]\n",
    "            elif 'but' in r:\n",
    "                religion_modifier_extracted = r.split('but')[1]\n",
    "            \n",
    "            religion_modifiers.append(religion_modifier_extracted)\n",
    "\n",
    "\n",
    "        religion_types = [*set(religion_types)] # create list of \"base\" religions\n",
    "\n",
    "\n",
    "        religion_modifiers = [*set(religion_modifiers)] # create list of religion modifiers\n",
    "\n",
    "\n",
    "        RELIGION_TYPES = religion_types\n",
    "        RELIGION_MODIFIERS = religion_modifiers\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['religion'])\n",
    "\n",
    "        relgion_encoded_header = ['religion_type', 'religion_modifier']\n",
    "\n",
    "        # Add col header\n",
    "        for rel_col in relgion_encoded_header:\n",
    "            df[rel_col] = np.nan\n",
    "\n",
    "        # Filer\n",
    "        def filter_religion_type(row_religion):    \n",
    "            # compare all extracted to current row in df\n",
    "            for type in RELIGION_TYPES:\n",
    "                if type in row_religion:\n",
    "                    # match\n",
    "                    return type\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "        # Filter\n",
    "        def filter_religion_modifier(row_religion):    \n",
    "            # compare all extracted to current row in df\n",
    "            for relmodifier in RELIGION_MODIFIERS:\n",
    "                if relmodifier in row_religion:\n",
    "                    # match\n",
    "                    return relmodifier\n",
    "            # no match\n",
    "            return np.nan\n",
    "\n",
    "        # Hot encoding for both offspring cols\n",
    "        df['religion_type'] = df.apply(lambda x: filter_religion_type(x['religion']), axis=1)\n",
    "        df['religion_modifier'] = df.apply(lambda x: filter_religion_modifier(x['religion']), axis=1)\n",
    "\n",
    "        ################## COMMENT OUT FOR FRONTEND\n",
    "        df.dropna(inplace=True, subset=['religion_type'])\n",
    "        df.dropna(inplace=True, subset=['religion_modifier'])\n",
    "\n",
    "\n",
    "        # Encode religion_type\n",
    "        religion_type_encoder = LabelEncoder()\n",
    "        religion_type_encoder.fit(df['religion_type'])\n",
    "        encoded_col_religion_type = religion_type_encoder.transform(df['religion_type'])\n",
    "        df['religion_type'] = encoded_col_religion_type\n",
    "\n",
    "        # Encode religion_modifier\n",
    "        religion_modifier_encoder = LabelEncoder()\n",
    "        religion_modifier_encoder.fit(df['religion_modifier'])\n",
    "        encoded_col_religion_modifier = religion_modifier_encoder.transform(df['religion_modifier'])\n",
    "        df['religion_modifier'] = encoded_col_religion_modifier\n",
    "\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('religion', axis=1)\n",
    "\n",
    "\n",
    "    if 'sex' in columns:\n",
    "        ### SEX ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['sex'])\n",
    "\n",
    "        # Encode drugs modifier\n",
    "        sex_encoder = LabelEncoder()\n",
    "        sex_encoder.fit(df['sex'])\n",
    "        encoded_col_sex = sex_encoder.transform(df['sex'])\n",
    "        df['sex'] = encoded_col_sex\n",
    "\n",
    "\n",
    "    if 'sign' in columns:\n",
    "        ### SIGN ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['sign'])\n",
    "\n",
    "\n",
    "        # Extract only sign\n",
    "        df['sign_extracted'] = df['sign'].str.split(' ').str[0]\n",
    "\n",
    "        # Extract sign modifier\n",
    "        df['sign_modifier_extracted'] = df['sign'].str.split(' ').str[1:]\n",
    "        df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y) # replace empty lists with ''\n",
    "        df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: ' '.join(y) if len(y)!=0 else y) # join list of strings together\n",
    "        df['sign_modifier_extracted'] = df['sign_modifier_extracted'].str.replace(ZODIAC_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "        ################## COMMENT OUT FOR FRONTEND\n",
    "        # Encode sign\n",
    "        sign_encoder = LabelEncoder()\n",
    "        sign_encoder.fit(df['sign_extracted'])\n",
    "        encoded_col_sign = sign_encoder.transform(df['sign_extracted'])\n",
    "        df['sign_extracted'] = encoded_col_sign\n",
    "\n",
    "        # Encode sign modifier\n",
    "        sign_modifier_encoder = LabelEncoder()\n",
    "        sign_modifier_encoder.fit(df['sign_modifier_extracted'])\n",
    "        encoded_col_sign_modifier = sign_modifier_encoder.transform(df['sign_modifier_extracted'])\n",
    "        df['sign_modifier_extracted'] = encoded_col_sign_modifier\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('sign', axis=1)\n",
    "\n",
    "\n",
    "    if 'smokes' in columns:\n",
    "        ### SMOKES ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['smokes'])\n",
    "\n",
    "        # Encode smokes modifier\n",
    "        smokes_encoder = LabelEncoder()\n",
    "        smokes_encoder.fit(df['smokes'])\n",
    "        encoded_col_smokes = smokes_encoder.transform(df['smokes'])\n",
    "        df['smokes'] = encoded_col_smokes\n",
    "\n",
    "\n",
    "    if 'speaks' in columns:\n",
    "        ### SPEAKS ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['speaks'])\n",
    "\n",
    "        languages = df.speaks.unique()\n",
    "\n",
    "        language = []\n",
    "        language_level = []\n",
    "\n",
    "        for l in languages:\n",
    "            entries = l.split(', ')\n",
    "            for e in entries:\n",
    "\n",
    "                # at least on entry that has a modifier\n",
    "                if e.find('(') != -1:\n",
    "                    # extract modifier\n",
    "                    res = e[e.find('(')+1:e.find(')')]\n",
    "                    \n",
    "                    # check if modifier can be appended\n",
    "                    if res not in language_level:\n",
    "                        language_level.append(res)\n",
    "                    \n",
    "                    # check if language can be appended\n",
    "                    if e[:e.find(' ')]:\n",
    "                        if e[:e.find(' ')] not in language:\n",
    "                            language.append(e[:e.find(' ')])\n",
    "                \n",
    "                # no modifier\n",
    "                else:\n",
    "                    # check if language can be appended\n",
    "                    if e not in language:\n",
    "                        language.append(e)\n",
    "\n",
    "\n",
    "        SPEAKS_LANGUAGE = language\n",
    "        SPEAKS_LANGUAGE_LEVEL = language_level\n",
    "\n",
    "        speaks_encoded_header = [l.replace(' ', '_') for l in SPEAKS_LANGUAGE]\n",
    "\n",
    "        # Add col header\n",
    "        for speaks_col in speaks_encoded_header:\n",
    "            df['speaks_'+speaks_col] = np.nan\n",
    "\n",
    "        speaks_encoded_header = ['speaks_'+l for l in speaks_encoded_header]\n",
    "        speaks_encoded_header = [l.replace(' ', '_') for l in speaks_encoded_header]\n",
    "\n",
    "\n",
    "        # Filter\n",
    "        def filter_speaks(s, row_speaks):    \n",
    "            # compare all extracted to current row in df\n",
    "\n",
    "            # split string into list of multiple langues + modifier\n",
    "            rs = row_speaks.split(', ')\n",
    "\n",
    "            # check if language s (current col) is in this list\n",
    "            res = [i for i in rs if s in i]\n",
    "            if len(res) != 0:\n",
    "                # modifier:\n",
    "                if '(fluently)' in res[0]:\n",
    "                    return 4\n",
    "                if '(ok)' in res[0]:\n",
    "                    return 3\n",
    "                if '(poorly)' in res[0]:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 2\n",
    "            else:\n",
    "                return 0 # maybe change to np.nan\n",
    "\n",
    "\n",
    "        # Hot encoding for all speaks cols\n",
    "        for (speaks_encoded_header_col, s) in zip(speaks_encoded_header, SPEAKS_LANGUAGE):\n",
    "            df[speaks_encoded_header_col] = df.apply(lambda x: filter_speaks(s, x['speaks']), axis=1)\n",
    "\n",
    "\n",
    "        # Drop reduandant cols\n",
    "        df = df.drop('speaks', axis=1)\n",
    "\n",
    "    if 'status' in columns:\n",
    "        ### STATUS ###\n",
    "\n",
    "        # Remove nan's\n",
    "        df.dropna(inplace=True, subset=['status'])\n",
    "\n",
    "        # Encode drugs modifier\n",
    "        status_encoder = LabelEncoder()\n",
    "        status_encoder.fit(df['status'])\n",
    "        encoded_col_status = status_encoder.transform(df['status'])\n",
    "        df['status'] = encoded_col_status\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/profiles_revised.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m all_columns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbody_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdiet\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdrinks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdrugs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meducation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moffspring\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpets\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m        \u001b[39m'\u001b[39m\u001b[39msex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msmokes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/profiles_revised.csv')\n",
    "all_columns = df.columns\n",
    "\n",
    "cols = ['age', 'body_type', 'diet', 'drinks', 'drugs', 'education',\n",
    "       'height', 'offspring', 'orientation', 'pets',\n",
    "       'sex', 'sign', 'smokes', 'status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age  body_type  diet  drinks  drugs  \\\n",
      "0     -1.089092          0     0       4      0   \n",
      "1      0.386157          2     3       2      2   \n",
      "7     -0.246093          2     0       4      0   \n",
      "14    -0.351468         10     0       4      0   \n",
      "22    -0.140718          4     0       4      0   \n",
      "...         ...        ...   ...     ...    ...   \n",
      "59838 -0.035343          4     0       4      2   \n",
      "59852 -0.456842          3     0       4      0   \n",
      "59902 -0.772967          3     3       3      0   \n",
      "59922 -1.194466         10     5       4      2   \n",
      "59944 -0.667592          1     0       4      1   \n",
      "\n",
      "                                      ethnicity    height  income  \\\n",
      "0                                  asian, white  1.695729      -1   \n",
      "1                                         white  0.428660   80000   \n",
      "7                                         white -0.838410      -1   \n",
      "14                      hispanic / latin, white -1.598651   50000   \n",
      "22                                        white  0.175246      -1   \n",
      "...                                         ...       ...     ...   \n",
      "59838                              white, other -0.078168   50000   \n",
      "59852                                     white -0.584996      -1   \n",
      "59902  native american, hispanic / latin, white -0.331582      -1   \n",
      "59922                                       NaN -0.838410      -1   \n",
      "59944                              asian, black  1.188902      -1   \n",
      "\n",
      "                               job  orientation  ... status  diet_modifier  \\\n",
      "0                   transportation            2  ...      3              2   \n",
      "1             hospitality / travel            2  ...      3              1   \n",
      "7      artistic / musical / writer            2  ...      3              1   \n",
      "14                           other            2  ...      3              1   \n",
      "22          executive / management            2  ...      3              1   \n",
      "...                            ...          ...  ...    ...            ...   \n",
      "59838            medicine / health            2  ...      3              1   \n",
      "59852    clerical / administrative            0  ...      3              0   \n",
      "59902                      student            2  ...      3              1   \n",
      "59922                      student            2  ...      3              0   \n",
      "59944            medicine / health            2  ...      3              1   \n",
      "\n",
      "       education_status_extracted education_institution_extracted  \\\n",
      "0                               2                               0   \n",
      "1                               2                               6   \n",
      "7                               1                               0   \n",
      "14                              2                               0   \n",
      "22                              1                               0   \n",
      "...                           ...                             ...   \n",
      "59838                           1                               5   \n",
      "59852                           2                               3   \n",
      "59902                           1                               6   \n",
      "59922                           2                               0   \n",
      "59944                           2                               0   \n",
      "\n",
      "       offspring_status  offspring_future  pets_cats  pets_dogs  \\\n",
      "0                     0                 1          1          1   \n",
      "1                     0                 1          1          1   \n",
      "7                     0                 2          1          1   \n",
      "14                    0                 2          0          1   \n",
      "22                    0                 1          1          1   \n",
      "...                 ...               ...        ...        ...   \n",
      "59838                 0                 1          1          1   \n",
      "59852                 0                 1          1          1   \n",
      "59902                 0                 1          0          0   \n",
      "59922                 0                 0          1          1   \n",
      "59944                 0                 2          1          1   \n",
      "\n",
      "       sign_extracted  sign_modifier_extracted  \n",
      "0                   4                        0  \n",
      "1                   2                        0  \n",
      "7                   8                        0  \n",
      "14                 10                        0  \n",
      "22                  8                        3  \n",
      "...               ...                      ...  \n",
      "59838              10                        2  \n",
      "59852               8                        2  \n",
      "59902               9                        2  \n",
      "59922               2                        3  \n",
      "59944               5                        2  \n",
      "\n",
      "[3389 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(cols, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1810ffdbcb71ae5fcf06025e105de04d63893ffcafad0347f47a9509230b92c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
