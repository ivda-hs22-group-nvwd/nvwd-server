{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # DEBUG\n",
    "from glob import glob\n",
    "from pandas_profiling import ProfileReport\n",
    "import yaml\n",
    "import re\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas_profiling import ProfileReport\n",
    "import json\n",
    "import category_encoders\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ABS_SRC = os.getcwd()\n",
    "PATH_REL = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/profiles_revised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTS\n",
    "ZODIAC_STRING_REPLACMENT = '&rsquo;' # corresponds to \" ' \"\n",
    "OFFSPRING_STRING_REPLACMENT = '&rsquo;' # corresponds to \" ' \"\n",
    "cols = df.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('preprocessing'):\n",
    "    os.makedirs('preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_col_values(list, filename):\n",
    "    file_path = os.path.relpath(\"preprocessing\")\n",
    "    with open(file_path+'/{}.txt'.format(filename), 'w') as fp:\n",
    "        for element in list:\n",
    "            fp.write(\"{}\\n\".format(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique col values\n",
    "for col in cols:\n",
    "    print_col_values(list=df[col].unique(), filename=col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title='Pandas Profilign Report')\n",
    "# profile.to_notebook_iframe()\n",
    "# profile.to_file(\"pandas_profiling_data_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard scaler\n",
    "def std_scaler(df, col_names):\n",
    "    scaled_features = df.copy()\n",
    " \n",
    "    features = scaled_features[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    " \n",
    "    scaled_features[col_names] = features\n",
    "\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "# Using min/max scaler\n",
    "def minmax_scaler(df, col_names):\n",
    "    scaled_features = df.copy()\n",
    " \n",
    "    features = scaled_features[col_names]\n",
    "    scaler = MinMaxScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    " \n",
    "    scaled_features[col_names] = features\n",
    "\n",
    "    return scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['age'])\n",
    "\n",
    "# Scale\n",
    "df = std_scaler(df, ['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['body_type'])\n",
    "\n",
    "# Encode body type\n",
    "body_type_encoder = LabelEncoder()\n",
    "body_type_encoder.fit(df['body_type'])\n",
    "encoded_col_body_type = body_type_encoder.transform(df['body_type'])\n",
    "df['body_type'] = encoded_col_body_type\n",
    "\n",
    "# Todo: Consultation whether mapping (clearly unhealthy => -1, not optimal/unknown => 0, else => +1) justifiable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['diet'])\n",
    "\n",
    "# Extract only diet\n",
    "df['diet_extracted'] = df['diet'].str.split(' ').str[-1]\n",
    "\n",
    "# Extract diet modifier\n",
    "df['diet_modifier_extracted'] = df['diet'].str.split(' ').str[:-1]\n",
    "df['diet_modifier_extracted'] = df['diet_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y[0]) # replace empty lists with '' and extract term from list\n",
    "\n",
    "# Todo: Consultation whether further mapping makes sense\n",
    "\n",
    "# Encode diet\n",
    "diet_encoder = LabelEncoder()\n",
    "diet_encoder.fit(df['diet_extracted'])\n",
    "encoded_col_diet = diet_encoder.transform(df['diet_extracted'])\n",
    "df['diet'] = encoded_col_diet\n",
    "\n",
    "# Encode diet modifier\n",
    "diet_modifier_encoder = LabelEncoder()\n",
    "diet_modifier_encoder.fit(df['diet_modifier_extracted'])\n",
    "encoded_col_diet_modifier = diet_modifier_encoder.transform(df['diet_modifier_extracted'])\n",
    "df['diet_modifier'] = encoded_col_diet_modifier\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('diet_extracted', axis=1)\n",
    "df = df.drop('diet_modifier_extracted', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['drinks'])\n",
    "\n",
    "# Encode drinks modifier\n",
    "drinks_encoder = LabelEncoder()\n",
    "drinks_encoder.fit(df['drinks'])\n",
    "encoded_col_drinks = drinks_encoder.transform(df['drinks'])\n",
    "df['drinks'] = encoded_col_drinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['drugs'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "drinks_encoder = LabelEncoder()\n",
    "drinks_encoder.fit(df['drugs'])\n",
    "encoded_col_drugs = drinks_encoder.transform(df['drugs'])\n",
    "df['drugs'] = encoded_col_drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['education'])\n",
    "\n",
    "\n",
    "# Extract only education institution\n",
    "# todo find better solution to use the dedicated mapper in naming.yaml\n",
    "def education_institution_mapper(x):\n",
    "    if 'college/university' in x:\n",
    "        return 'college/university'\n",
    "    if 'two-year college' in x:\n",
    "        return 'two-year college'\n",
    "    if 'masters program' in x:\n",
    "        return 'masters program'\n",
    "    if 'ph.d program' in x:\n",
    "        return 'ph.d program'\n",
    "    if 'high school' in x:\n",
    "        return 'high school'\n",
    "    if 'law school' in x:\n",
    "        return 'law school'\n",
    "    if 'med school' in x:\n",
    "        return 'med school'\n",
    "    if 'space camp' in x:\n",
    "        return 'space camp'\n",
    "\n",
    "# Extract only education status\n",
    "def education_status_mapper(x):\n",
    "    if 'dropped out of' in x:\n",
    "        return 'dropped out of'\n",
    "    if 'working on' in x:\n",
    "        return 'working on'\n",
    "    if 'graduated from' in x:\n",
    "        return 'graduated from'\n",
    "\n",
    "\n",
    "df['education_status_extracted'] = df['education'].apply(lambda x: education_status_mapper(x))\n",
    "df['education_institution_extracted'] = df['education'].apply(lambda x: education_institution_mapper(x))\n",
    "\n",
    "\n",
    "# Encode education_status\n",
    "education_status_encoder = LabelEncoder()\n",
    "education_status_encoder.fit(df['education_status_extracted'])\n",
    "encoded_col_education_status = education_status_encoder.transform(df['education_status_extracted'])\n",
    "df['education_status_extracted'] = encoded_col_education_status\n",
    "\n",
    "# Encode diet modifier\n",
    "education_institution_encoder = LabelEncoder()\n",
    "education_institution_encoder.fit(df['education_institution_extracted'])\n",
    "encoded_col_education_institution = education_institution_encoder.transform(df['education_institution_extracted'])\n",
    "df['education_institution_extracted'] = encoded_col_education_institution\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('education', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all ethnicities categories\n",
    "# Get all distinct values for the ethnicity  col\n",
    "ethnicities = df.ethnicity.unique()\n",
    "\n",
    "# Clean\n",
    "ethnicities = [e for e in ethnicities if str(e) != 'nan'] # remove nan values\n",
    "\n",
    "# Extract all ethnicities combinations \n",
    "ethnicities = ', '.join(ethnicities)\n",
    "ethnicities = ethnicities.split(', ') \n",
    "ethnicities = [*set(ethnicities)] # create list of \"base\" ethnicities\n",
    "\n",
    "# Generate new header for encoded categories\n",
    "ethnicities_encoded_header = ['ethnicities_{}'.format(e.replace(' ', '_')) for e in ethnicities]\n",
    "\n",
    "\n",
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['ethnicity'])\n",
    "\n",
    "# Add col header\n",
    "for eth_col in ethnicities_encoded_header:\n",
    "    df[eth_col] = np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_ethnicities(col, row_ethnicities):\n",
    "    # extract all ethnicities from the col 'ethnicity'\n",
    "    row_ethnicities = row_ethnicities.split(', ')\n",
    "    \n",
    "    # compare all extracted to current row in df\n",
    "    for re in row_ethnicities:\n",
    "        # match\n",
    "        if re == col:\n",
    "            return 1\n",
    "    # no match\n",
    "    return 0\n",
    "\n",
    "# Hot encoding for all ethnicities cols\n",
    "for (ethnicities_encoded_header_col, e) in zip(ethnicities_encoded_header, ethnicities):\n",
    "    df[ethnicities_encoded_header_col] = df.apply(lambda x: filter_ethnicities(e, x['ethnicity']), axis=1)\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('ethnicity', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['height'])\n",
    "\n",
    "# Scale\n",
    "df = std_scaler(df, ['height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKIP INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 entries\n",
    "#df['income'] = df['income'].apply(lambda y: np.nan if y==-1 else y) # replace -1 with nan\n",
    "# Todo: Maybe insert non nan but average income (only 5k values after that)\n",
    "\n",
    "# Remove nan's\n",
    "#df.dropna(inplace=True, subset=['income'])\n",
    "\n",
    "# Scale\n",
    "#df = std_scaler(df, ['income'])\n",
    "#df\n",
    "\n",
    "df = df.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['job'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "job_encoder = LabelEncoder()\n",
    "job_encoder.fit(df['job'])\n",
    "encoded_col_job = job_encoder.transform(df['job'])\n",
    "df['job'] = encoded_col_job\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all offspring categories\n",
    "# todo: automate\n",
    "\n",
    "OFFSPRING_STATUS_ORIG = [\n",
    "    'doesn\\'t have kids', 'has a kid', 'has kids'] # STATUS\n",
    "\n",
    "\n",
    "OFFSPRING_FUTURE_ORIG = [\n",
    "    'and doesn\\'t want any', 'doesn\\'t want kids', 'but doesn\\'t want more',\n",
    "    'but might want them', 'might want kids', 'and might want more',\n",
    "    'wants kids', 'but wants them', 'and wants more'] # FUTURE\n",
    "\n",
    "OFFSPRING_FUTURE = [\n",
    "    'doesn\\'t want',\n",
    "    'might want',\n",
    "    'wants'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['offspring'])\n",
    "\n",
    "df['offspring'] = df['offspring'].str.replace(OFFSPRING_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "offspring_encoded_header = ['offspring_status', 'offspring_future']\n",
    "\n",
    "# Add col header\n",
    "for off_col in offspring_encoded_header:\n",
    "    df[off_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_offspring_status(row_offspring):    \n",
    "    # compare all extracted to current row in df\n",
    "    for status in OFFSPRING_STATUS_ORIG:\n",
    "        if status in row_offspring:\n",
    "            # match\n",
    "            return status\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_offspring_future(row_offspring):    \n",
    "    # compare all extracted to current row in df\n",
    "    for future in OFFSPRING_FUTURE:\n",
    "        if future in row_offspring:\n",
    "            # match\n",
    "            return future\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['offspring_status'] = df.apply(lambda x: filter_offspring_status(x['offspring']), axis=1)\n",
    "df['offspring_future'] = df.apply(lambda x: filter_offspring_future(x['offspring']), axis=1)\n",
    "\n",
    "df.dropna(inplace=True, subset=['offspring_status'])\n",
    "df.dropna(inplace=True, subset=['offspring_future'])\n",
    "\n",
    "\n",
    "# Encode offspring_status\n",
    "offspring_status_encoder = LabelEncoder()\n",
    "offspring_status_encoder.fit(df['offspring_status'])\n",
    "encoded_col_offspring_status = offspring_status_encoder.transform(df['offspring_status'])\n",
    "df['offspring_status'] = encoded_col_offspring_status\n",
    "\n",
    "# Encode offspring_future\n",
    "offspring_future_encoder = LabelEncoder()\n",
    "offspring_future_encoder.fit(df['offspring_future'])\n",
    "encoded_col_offspring_future = offspring_future_encoder.transform(df['offspring_future'])\n",
    "df['offspring_future'] = encoded_col_offspring_future\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('offspring', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['orientation'])\n",
    "\n",
    "# Encode orientation\n",
    "orientation_encoder = LabelEncoder()\n",
    "orientation_encoder.fit(df['orientation'])\n",
    "encoded_col_orientation = orientation_encoder.transform(df['orientation'])\n",
    "df['orientation'] = encoded_col_orientation\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all pets categories\n",
    "# todo: automate\n",
    "\n",
    "PETS_CATS = [\n",
    "    'has cats', 'likes cats', 'dislikes cats']\n",
    "\n",
    "PETS_DOGS = [\n",
    "    'has dogs', 'likes dogs', 'dislikes dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['pets'])\n",
    "\n",
    "\n",
    "pets_encoded_header = ['pets_cats', 'pets_dogs']\n",
    "\n",
    "# Add col header\n",
    "for pets_col in pets_encoded_header:\n",
    "    df[pets_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_pets_cats(row_pets):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relation in PETS_CATS:\n",
    "        if relation in row_pets:\n",
    "            # match\n",
    "            return relation\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_pets_dogs(row_pets):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relation in PETS_DOGS:\n",
    "        if relation in row_pets:\n",
    "            # match\n",
    "            return relation\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['pets_cats'] = df.apply(lambda x: filter_pets_cats(x['pets']), axis=1)\n",
    "df['pets_dogs'] = df.apply(lambda x: filter_pets_dogs(x['pets']), axis=1)\n",
    "\n",
    "df.dropna(inplace=True, subset=['pets_cats'])\n",
    "df.dropna(inplace=True, subset=['pets_dogs'])\n",
    "\n",
    "\n",
    "# Encode pets_cats\n",
    "pets_cats_encoder = LabelEncoder()\n",
    "pets_cats_encoder.fit(df['pets_cats'])\n",
    "encoded_col_pets_cats = pets_cats_encoder.transform(df['pets_cats'])\n",
    "df['pets_cats'] = encoded_col_pets_cats\n",
    "\n",
    "# Encode pets_dogs\n",
    "pets_dogs_encoder = LabelEncoder()\n",
    "pets_dogs_encoder.fit(df['pets_dogs'])\n",
    "encoded_col_pets_dogs = pets_dogs_encoder.transform(df['pets_dogs'])\n",
    "df['pets_dogs'] = encoded_col_pets_dogs\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('pets', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all offspring categories\n",
    "# todo: automate\n",
    "\n",
    "# Extract all religion categories\n",
    "# Get all distinct values for the religion  col\n",
    "religion = df.religion.unique()\n",
    "\n",
    "# Clean\n",
    "religion = [r for r in religion if str(r) != 'nan'] # remove nan values\n",
    "\n",
    "# Extract all religion types\n",
    "religion_types = []\n",
    "religion_modifiers = [] \n",
    "for r in religion:\n",
    "    # extraxt first half: up to 'and' or 'but'\n",
    "    if 'and' in r:\n",
    "        religion_extracted = r.split('and')[0]\n",
    "    elif 'but' in r:\n",
    "        religion_extracted = r.split('but')[0]\n",
    "    else:\n",
    "        religion_extracted = r\n",
    "    religion_types.append(religion_extracted)\n",
    "   \n",
    "for r in religion:\n",
    "    # extraxt first half: up to 'and' or 'but'\n",
    "    if 'and' in r:\n",
    "        religion_modifier_extracted = r.split('and')[1]\n",
    "    elif 'but' in r:\n",
    "        religion_modifier_extracted = r.split('but')[1]\n",
    "    \n",
    "    religion_modifiers.append(religion_modifier_extracted)\n",
    "\n",
    "\n",
    "religion_types = [*set(religion_types)] # create list of \"base\" religions\n",
    "\n",
    "\n",
    "religion_modifiers = [*set(religion_modifiers)] # create list of religion modifiers\n",
    "\n",
    "\n",
    "RELIGION_TYPES = religion_types\n",
    "\n",
    "\n",
    "RELIGION_MODIFIERS = religion_modifiers\n",
    "\n",
    "print(RELIGION_TYPES)\n",
    "print(RELIGION_MODIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['religion'])\n",
    "\n",
    "relgion_encoded_header = ['religion_type', 'religion_modifier']\n",
    "\n",
    "# Add col header\n",
    "for rel_col in relgion_encoded_header:\n",
    "    df[rel_col] = np.nan\n",
    "\n",
    "# Filer\n",
    "def filter_religion_type(row_religion):    \n",
    "    # compare all extracted to current row in df\n",
    "    for type in RELIGION_TYPES:\n",
    "        if type in row_religion:\n",
    "            # match\n",
    "            return type\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Filter\n",
    "def filter_religion_modifier(row_religion):    \n",
    "    # compare all extracted to current row in df\n",
    "    for relmodifier in RELIGION_MODIFIERS:\n",
    "        if relmodifier in row_religion:\n",
    "            # match\n",
    "            return relmodifier\n",
    "    # no match\n",
    "    return np.nan\n",
    "\n",
    "# Hot encoding for both offspring cols\n",
    "df['religion_type'] = df.apply(lambda x: filter_religion_type(x['religion']), axis=1)\n",
    "df['religion_modifier'] = df.apply(lambda x: filter_religion_modifier(x['religion']), axis=1)\n",
    "\n",
    "################## COMMENT OUT FOR FRONTEND\n",
    "df.dropna(inplace=True, subset=['religion_type'])\n",
    "df.dropna(inplace=True, subset=['religion_modifier'])\n",
    "\n",
    "\n",
    "# Encode religion_type\n",
    "religion_type_encoder = LabelEncoder()\n",
    "religion_type_encoder.fit(df['religion_type'])\n",
    "encoded_col_religion_type = religion_type_encoder.transform(df['religion_type'])\n",
    "df['religion_type'] = encoded_col_religion_type\n",
    "\n",
    "# Encode religion_modifier\n",
    "religion_modifier_encoder = LabelEncoder()\n",
    "religion_modifier_encoder.fit(df['religion_modifier'])\n",
    "encoded_col_religion_modifier = religion_modifier_encoder.transform(df['religion_modifier'])\n",
    "df['religion_modifier'] = encoded_col_religion_modifier\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('religion', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['sex'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "sex_encoder = LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "encoded_col_sex = sex_encoder.transform(df['sex'])\n",
    "df['sex'] = encoded_col_sex\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['sign'])\n",
    "\n",
    "\n",
    "# Extract only sign\n",
    "df['sign_extracted'] = df['sign'].str.split(' ').str[0]\n",
    "\n",
    "# Extract sign modifier\n",
    "df['sign_modifier_extracted'] = df['sign'].str.split(' ').str[1:]\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: '' if len(y)==0 else y) # replace empty lists with ''\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].apply(lambda y: ' '.join(y) if len(y)!=0 else y) # join list of strings together\n",
    "df['sign_modifier_extracted'] = df['sign_modifier_extracted'].str.replace(ZODIAC_STRING_REPLACMENT,'\\'')  # replace \n",
    "\n",
    "################## COMMENT OUT FOR FRONTEND\n",
    "# Encode sign\n",
    "sign_encoder = LabelEncoder()\n",
    "sign_encoder.fit(df['sign_extracted'])\n",
    "encoded_col_sign = sign_encoder.transform(df['sign_extracted'])\n",
    "df['sign_extracted'] = encoded_col_sign\n",
    "\n",
    "# Encode sign modifier\n",
    "sign_modifier_encoder = LabelEncoder()\n",
    "sign_modifier_encoder.fit(df['sign_modifier_extracted'])\n",
    "encoded_col_sign_modifier = sign_modifier_encoder.transform(df['sign_modifier_extracted'])\n",
    "df['sign_modifier_extracted'] = encoded_col_sign_modifier\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('sign', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['smokes'])\n",
    "\n",
    "# Encode smokes modifier\n",
    "smokes_encoder = LabelEncoder()\n",
    "smokes_encoder.fit(df['smokes'])\n",
    "encoded_col_smokes = smokes_encoder.transform(df['smokes'])\n",
    "df['smokes'] = encoded_col_smokes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['speaks'])\n",
    "\n",
    "languages = df.speaks.unique()\n",
    "\n",
    "language = []\n",
    "language_level = []\n",
    "\n",
    "for l in languages:\n",
    "    entries = l.split(', ')\n",
    "    for e in entries:\n",
    "\n",
    "        # at least on entry that has a modifier\n",
    "        if e.find('(') != -1:\n",
    "            # extract modifier\n",
    "            res = e[e.find('(')+1:e.find(')')]\n",
    "            \n",
    "            # check if modifier can be appended\n",
    "            if res not in language_level:\n",
    "                language_level.append(res)\n",
    "            \n",
    "            # check if language can be appended\n",
    "            if e[:e.find(' ')]:\n",
    "                if e[:e.find(' ')] not in language:\n",
    "                    language.append(e[:e.find(' ')])\n",
    "        \n",
    "        # no modifier\n",
    "        else:\n",
    "            # check if language can be appended\n",
    "            if e not in language:\n",
    "                language.append(e)\n",
    "\n",
    "\n",
    "\n",
    "SPEAKS_LANGUAGE = language\n",
    "\n",
    "SPEAKS_LANGUAGE_LEVEL = language_level\n",
    "print(SPEAKS_LANGUAGE)\n",
    "print(SPEAKS_LANGUAGE_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaks_encoded_header = [l.replace(' ', '_') for l in SPEAKS_LANGUAGE]\n",
    "\n",
    "# Add col header\n",
    "for speaks_col in speaks_encoded_header:\n",
    "    df['speaks_'+speaks_col] = np.nan\n",
    "\n",
    "speaks_encoded_header = ['speaks_'+l for l in speaks_encoded_header]\n",
    "speaks_encoded_header = [l.replace(' ', '_') for l in speaks_encoded_header]\n",
    "\n",
    "\n",
    "# Filter\n",
    "def filter_speaks(s, row_speaks):    \n",
    "    # compare all extracted to current row in df\n",
    "\n",
    "    # split string into list of multiple langues + modifier\n",
    "    rs = row_speaks.split(', ')\n",
    "\n",
    "    # check if language s (current col) is in this list\n",
    "    res = [i for i in rs if s in i]\n",
    "    if len(res) != 0:\n",
    "        # modifier:\n",
    "        if '(fluently)' in res[0]:\n",
    "            return 4\n",
    "        if '(ok)' in res[0]:\n",
    "            return 3\n",
    "        if '(poorly)' in res[0]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        return 0 # maybe change to np.nan\n",
    "\n",
    "\n",
    "# Hot encoding for all speaks cols\n",
    "for (speaks_encoded_header_col, s) in zip(speaks_encoded_header, SPEAKS_LANGUAGE):\n",
    "    df[speaks_encoded_header_col] = df.apply(lambda x: filter_speaks(s, x['speaks']), axis=1)\n",
    "\n",
    "\n",
    "# Drop reduandant cols\n",
    "df = df.drop('speaks', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan's\n",
    "df.dropna(inplace=True, subset=['status'])\n",
    "\n",
    "# Encode drugs modifier\n",
    "status_encoder = LabelEncoder()\n",
    "status_encoder.fit(df['status'])\n",
    "encoded_col_status = status_encoder.transform(df['status'])\n",
    "df['status'] = encoded_col_status\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Desired format\n",
    "# {name: \"age\", sets: [19,26,34...]},\n",
    "# {name: \"job\", sets: ['B', 'C', 'D']},\n",
    "# {name: \"sign\", sets: [\"ariel\", \"batman\", \"idc\"...]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_json('df_cleansed_removed_income_split.json', orient='split')\n",
    "# df.T.to_json('df_cleansed_removed_income_values.json', orient='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df_cleansed_removed_income_split.json')\n",
    "data = json.load(f)\n",
    "\n",
    "master_data = []\n",
    "for index, attribute in enumerate(data['index']):\n",
    "    dict = {}\n",
    "    dict[\"name\"] = attribute\n",
    "    dict[\"sets\"] = data['data'][index]\n",
    "    master_data.append(dict)\n",
    "master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt', 'w') as f:\n",
    "    for line in master_data:\n",
    "        f.write(f\"{line},\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('okcupid.db')\n",
    "df.to_sql('okcupid', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_someAttempt = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_someAttempt =df_someAttempt[['age', 'height', 'body_type', 'diet', 'drinks', 'drugs', 'orientation', 'sex', 'smokes', 'status', 'religion_type', 'job', 'sign_extracted', 'pets_cats', 'pets_dogs', 'offspring_status', 'offspring_future'  ]] #offspring / job /sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['income'], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_someAttempt = df_someAttempt.dropna().reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_someAttempt.to_json(\"test2.json\", orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_someAttempt.to_json(\"test3.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compString = ''\n",
    "for index, attribute in df_someAttempt.iterrows():\n",
    "    dataString = f'{{ \"name\" : \"Person{index}\", \"age\": {attribute.age}, \"sex\": \"{attribute.sex}\", \"height\": {attribute.height}, \"sets\": ['\n",
    "    for i, a in enumerate(attribute):\n",
    "        if (i != 0 and i != 1 and i != 7):\n",
    "            dataString += f'\"{attribute.index[i]} - {a}\"'\n",
    "        if i != len(attribute):\n",
    "            dataString += ','\n",
    "    dataString += ']},'\n",
    "    compString += dataString\n",
    "    with open('data_file.json', 'a') as f:\n",
    "        f.write(dataString + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('data.txt', 'w') as f:\n",
    "    for line in master_data:\n",
    "        f.write(f\"{compString},\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1810ffdbcb71ae5fcf06025e105de04d63893ffcafad0347f47a9509230b92c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
